{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cdff1d-c9cc-46ce-9c58-c9cb95614ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import additional utilities needed in this notebook.\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from typing import Dict, Sequence\n",
    "\n",
    "# Set default plotting style.\n",
    "sns.set()\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import argparse, glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110f470-986f-4755-aa4d-6f4a8ab27abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"C:\\\\Users\\\\azatv\\\\VSCProjects\\\\Second Python\\\\U3-5\\\\04_images\"\n",
    "image_files = sorted(glob.glob(os.path.join(input_path, \"**\", \"*.jpg\"), recursive=True))\n",
    "print(image_files)\n",
    "with Image.open(image_files[0]) as im:  # This returns a PIL image\n",
    "    image = np.array(im)  # We can convert it to a numpy array\n",
    "print(\"image data:\")\n",
    "print(f\"mode: {im.mode}; shape: {image.shape}; min: {image.min()}; max: {image.max()}; dtype: {image.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29a3807-5f92-46df-b701-6cbfd6424966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[120, 137, 163],\n",
       "        [121, 137, 163],\n",
       "        [121, 137, 163],\n",
       "        ...,\n",
       "        [118, 135, 165],\n",
       "        [118, 135, 165],\n",
       "        [116, 135, 165]],\n",
       "\n",
       "       [[120, 137, 165],\n",
       "        [121, 136, 165],\n",
       "        [121, 136, 165],\n",
       "        ...,\n",
       "        [118, 135, 165],\n",
       "        [118, 135, 165],\n",
       "        [116, 135, 167]],\n",
       "\n",
       "       [[118, 135, 161],\n",
       "        [120, 136, 162],\n",
       "        [120, 136, 162],\n",
       "        ...,\n",
       "        [121, 138, 164],\n",
       "        [121, 138, 164],\n",
       "        [121, 139, 163]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[114, 134, 159],\n",
       "        [115, 135, 160],\n",
       "        [115, 135, 160],\n",
       "        ...,\n",
       "        [101, 127, 154],\n",
       "        [100, 126, 153],\n",
       "        [101, 125, 151]],\n",
       "\n",
       "       [[114, 134, 159],\n",
       "        [115, 135, 160],\n",
       "        [115, 135, 160],\n",
       "        ...,\n",
       "        [101, 128, 155],\n",
       "        [101, 127, 154],\n",
       "        [101, 127, 152]],\n",
       "\n",
       "       [[115, 135, 162],\n",
       "        [114, 135, 162],\n",
       "        [114, 135, 162],\n",
       "        ...,\n",
       "        [102, 129, 156],\n",
       "        [101, 128, 155],\n",
       "        [102, 128, 153]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image \n",
    "# image_files = sorted(glob.glob(os.path.join(input_path, \"**\", \"*.jpg\"), recursive=True))\n",
    "# # Check number of found files\n",
    "# print(f\"Found {len(image_files)} image files\")\n",
    "\n",
    "# # Read first image file\n",
    "# with Image.open(image_files[0]) as im:  # This returns a PIL image\n",
    "#     image = np.array(im)  # We can convert it to a numpy array\n",
    "# print(\"image data:\")\n",
    "# print(f\"mode: {im.mode}; shape: {image.shape}; min: {image.min()}; max: {image.max()}; dtype: {image.dtype}\")\n",
    "\n",
    "# # We are dealing with image data, so each sample is high-dimensional and\n",
    "# # contains as many features as it has pixels. Pixel values range from 0 to 255\n",
    "# # in 3 color channels for RGB and in 1 channel for grayscale images. In case\n",
    "# # transparency is also stored, we have an additional channel (alpha).\n",
    "\n",
    "# #\n",
    "# # Check means and standard deviations of images\n",
    "# #\n",
    "\n",
    "# # We know how many images to expect, so we can already allocate numpy arrays to\n",
    "# # store mean and std values as float values and the folder_names of the folders.\n",
    "# # Since we want RGB images, we will collect the metrics for each channel,\n",
    "# # dropping the transparency information in case an image has an alpha channel.\n",
    "# means = np.zeros(shape=(len(image_files), 3))\n",
    "# stds = np.zeros(shape=(len(image_files), 3))\n",
    "# folder_names = []\n",
    "\n",
    "# # Loop through files, read them, and store mean, std and folder folder_name\n",
    "# for i, image_file in tqdm(enumerate(image_files), desc=\"Processing files\", total=len(image_files)):\n",
    "#     with Image.open(image_file) as im:\n",
    "#         image = np.array(im)\n",
    "#     # Check that we have RGB(A) images and drop the (potential) alpha channel\n",
    "#     assert len(image.shape) == 3 and image.shape[2] >= 3, f\"{image_file}: {image.shape}\"\n",
    "#     if image.shape[2] == 4:\n",
    "#         image = image[:, :, :-1]\n",
    "#     # Perform metric computations along axes 0 and 1 (height and width)\n",
    "#     means[i] = image.mean(axis=(0, 1))\n",
    "#     stds[i] = image.std(axis=(0, 1))\n",
    "#     folder_names.append(os.path.basename(os.path.dirname(image_file)))\n",
    "# folder_names = np.array(folder_names)\n",
    "\n",
    "# # It's a good idea to create save-points if computation takes a while. Here, we\n",
    "# # save the means, stds and folder_names that we computed.\n",
    "# import dill as pkl\n",
    "# import gzip\n",
    "\n",
    "# # Save our data in a compressed pickle file\n",
    "# with gzip.open(\"04_means_stds.pklz\", \"wb\") as f:\n",
    "#     pkl.dump(dict(means=means, stds=stds, folder_names=folder_names), file=f)\n",
    "\n",
    "# # Load precomputed data from the compressed pickle file\n",
    "# # with gzip.open(\"04_means_stds.pklz\", \"rb\") as f:\n",
    "# #     load_dict = pkl.load(f)\n",
    "# # means = load_dict[\"means\"]\n",
    "# # stds = load_dict[\"stds\"]\n",
    "# # folder_names = load_dict[\"folder_names\"]\n",
    "\n",
    "# # Now we want to visualize our data. We will use a pyplot 2D scatter plot.\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(ncols=3, figsize=(16, 5), sharex=True, sharey=True)\n",
    "# unique_folder_names, point_colors = np.unique(folder_names, return_inverse=True)\n",
    "# for i in range(3):\n",
    "#     scatter = axes[i].scatter(x=means[:, i], y=stds[:, i], c=point_colors, s=5, cmap=\"nipy_spectral\")\n",
    "#     axes[i].set_xlabel(\"mean\")\n",
    "#     axes[i].set_ylabel(\"standard deviation\")\n",
    "#     axes[i].grid(True)\n",
    "#     axes[i].set_title(f\"channel {i}\")\n",
    "# fig.legend(scatter.legend_elements()[0], unique_folder_names, loc=\"upper center\", ncol=16)\n",
    "# fig.savefig('mean_std.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d567c09-f7c0-4b63-8cf9-f48294d2cb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e714ee0e-8ae3-47ce-a436-8536c08a994b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13556\\1215889451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# if image.shape[2] == 4:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#             image = image[:, :, :-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#         # The original image dimension is (H, W, 3), but the pretrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#         # expects (3, H, W). Also, the data is expected to be in range [0, 1].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "image.shape\n",
    "# if image.shape[2] == 4:\n",
    "#             image = image[:, :, :-1]\n",
    "#         # The original image dimension is (H, W, 3), but the pretrained model\n",
    "#         # expects (3, H, W). Also, the data is expected to be in range [0, 1].\n",
    "#         image = torch.movedim(image, 2, 0) / 255\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d2825-dddc-4900-92fd-e82c7490a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
